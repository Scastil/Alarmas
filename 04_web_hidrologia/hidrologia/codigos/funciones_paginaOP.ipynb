{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys \n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "from wmf import wmf\n",
    "import numpy as np \n",
    "import glob \n",
    "import pylab as pl\n",
    "import json\n",
    "import MySQLdb\n",
    "import csv\n",
    "import matplotlib\n",
    "import matplotlib.font_manager\n",
    "from datetime import timedelta\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import matplotlib.dates as mdates\n",
    "import alarmas as al\n",
    "import simplekml\n",
    "import pykml\n",
    "\n",
    "from cpr import cpr\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mappingConfigtable(col_df):\n",
    "    ''' #Ejecuta funcion map(int,) sobre 'col_df' seteando los vacios para poderlos leer posteriormente.\n",
    "        #Funcion base.\n",
    "        #Argumentos:\n",
    "        col_df: df[column] del dfconfig.\n",
    "    ''' \n",
    "    lis=list(col_df)\n",
    "    for pos,value in enumerate(lis):\n",
    "        if value=='':\n",
    "            lis[pos]=''\n",
    "        elif len(value.split(','))>0:\n",
    "            lis[pos]=map(int,value.split(','))\n",
    "        else:\n",
    "            lis[pos]=map(int,value.split(','))\n",
    "    return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# entradas\n",
    "rutaconfig='/media/nicolas/Home/Jupyter/Soraya/git/Alarmas/04_web_hidrologia/hidrologia/informacion_sirenas.md'\n",
    "listconfig=al.get_rutesList(rutaconfig)\n",
    "\n",
    "#se trae la informacion de las estaciones desde CPR en un df.\n",
    "self=cpr.Nivel(90) #--> cualquier estacion para definir la clase.\n",
    "#df\n",
    "infoestaciones = self.infost\n",
    "risklevels_all=infoestaciones[['action_level','minor_flooding','moderate_flooding','major_flooding']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sirenas\n",
    "### Diccionario estático con todo lo de sirenas-alarmas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nombre alarmas\n",
    "- Nombre corrientes\n",
    "- Código niveles asociadas\n",
    "- KML de cuenca asociada para cada una.\n",
    "- (...KML red de drenaje...)\n",
    "- Mapas ubicación general: KMLs ubicacion de alarmas, KML microcuencas, KML municipios.\n",
    "\n",
    "**Nota:**\n",
    "- Las coordenadas de las alarmas con sus nombres, están en este msg:\n",
    "     \n",
    "        '../series/op/nombres_sirenas_op.msg'\n",
    "Este se va a actualizar sólo cuando se agreguen nuevas estaciones de nivel asociadas a alarmas, la mayoría del tiempo es estático.\n",
    "\n",
    "\n",
    "- Se incluyen las estaciones de nivel que están sobre la sirena o aguas arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_dfconfig2Json(rutaconfig,verbose=True):\n",
    "    ''' #Crea un JSON con la informacion de cada cuenca: estaciones de redes nivel, pluvio, meteo y kml's de cuencas.\n",
    "        Las estaciones asignadas y las rutas de los kml se sacan del configfile. \n",
    "        #Funcion no operacional.\n",
    "        #Argumentos:\n",
    "        rutaconfig: ruta del configfile.\n",
    "    '''\n",
    "    # rutaconfig='informacion_sirenas.md'\n",
    "    listconfig=al.get_rutesList(rutaconfig)\n",
    "    List=al.get_tables(listconfig,'-al')    \n",
    "    dfconfig=pd.DataFrame.from_records([i[1:-2].split('|') for i in List])\n",
    "    dfconfig.columns=dfconfig.iloc[0]\n",
    "    dfconfig.index=dfconfig['Codigo']\n",
    "    dfconfig=dfconfig.drop('Codigo')\n",
    "    dfconfig=dfconfig.drop('-al',axis=1)\n",
    "    dfconfig=dfconfig.drop('Codigo',axis=1)\n",
    "    dfconfig=dfconfig.drop(dfconfig.columns[-1],axis=1)\n",
    "    dfconfig.index.name=''\n",
    "    #####ASIGNACION DE ESTACIONES.\n",
    "    niveles_sirenas= al.mappingConfigtable(dfconfig['Est_Nivel'])#[[90,108],[173],[173],[259],[251,186],[265],[179],[246]]\n",
    "    niveles1_sirenas=al.mappingConfigtable(dfconfig['Est_Nivel1'])\n",
    "    pluvioadentro_sirenas=al.mappingConfigtable(dfconfig['Est_PluvioAdentro'])\n",
    "    pluvioafuera_sirenas=al.mappingConfigtable(dfconfig['Est_PluvioAfuera'])\n",
    "    meteoadentro_sirenas=al.mappingConfigtable(dfconfig['Est_MeteoAdentro'])\n",
    "    meteoafuera_sirenas=al.mappingConfigtable(dfconfig['Est_MeteoAfuera'])\n",
    "    N30m_sirenas=al.mappingConfigtable(dfconfig['Est_N30m'])\n",
    "    Tto_sirenas=al.mappingConfigtable(dfconfig['Est_Tto'])\n",
    "    #la cuenca La Lopez, está contenida en La Gallinaza - Barbosa, por eso se deja la ultima como la asociada a la alarma.\n",
    "    nombres_corrientes=list(dfconfig['Nombre_Quebrada'])#np.array(['Q. Dona Maria', 'Q. La Picacha','Q. La Picacha', 'Q. La Corrala', 'Q. La Gallinaza', 'Q. La Loca', 'Rio Medellin - La Inmaculada', 'Q. La Raya'])\n",
    "    nombres_sirenas=list(dfconfig['Nombre_Sirena'])\n",
    "    codigos_sirenas=list(dfconfig.index)\n",
    "\n",
    "    #Se toman las direcciones de los .kml de cada cuenca.\n",
    "    urlcuencas=glob.glob(al.get_ruta(listconfig,'ruta_KMLs')+'cuencas_alarmas/*')\n",
    "\n",
    "    # se crean dicts.\n",
    "    names_sirenas={};names_corrientes={};niv_sirenas={};niv1_sirenas={};pluvioadentro={};pluvioafuera={};meteoadentro={};meteoafuera={}\n",
    "    N30m={};Tto={};url_cuencas={}\n",
    "    for ind,sir in enumerate(codigos_sirenas):\n",
    "        #se obtiene y guarda los datos de las n_alarmas\n",
    "        names_sirenas.update({sir:nombres_sirenas[ind]})\n",
    "        names_corrientes.update({sir:nombres_corrientes[ind]})\n",
    "        niv_sirenas.update({sir:niveles_sirenas[ind]})\n",
    "        niv1_sirenas.update({sir:niveles1_sirenas[ind]})\n",
    "        pluvioadentro.update({sir:pluvioadentro_sirenas[ind]})\n",
    "        pluvioafuera.update({sir:pluvioafuera_sirenas[ind]})\n",
    "        meteoadentro.update({sir:meteoadentro_sirenas[ind]})\n",
    "        meteoafuera.update({sir:meteoafuera_sirenas[ind]})\n",
    "        N30m.update({sir:N30m_sirenas[ind]})\n",
    "        Tto.update({sir:Tto_sirenas[ind]})\n",
    "#         url_cuencas.update({sir:urlcuencas[ind]})\n",
    "\n",
    "    #Escribe diccionario para json\n",
    "    dictt={}\n",
    "    dictt.update({'Nombres Alarmas':names_sirenas})\n",
    "    dictt.update({'Nombres Corriente Asociada':names_corrientes})\n",
    "    dictt.update({'EstNivel':niv_sirenas})\n",
    "    dictt.update({'EstNivel1':niv1_sirenas})\n",
    "    dictt.update({'EstPluvioAdentro':pluvioadentro})\n",
    "    dictt.update({'EstPluvioAfuera':pluvioafuera})\n",
    "    dictt.update({'EstMeteoAdentro':meteoadentro})\n",
    "    dictt.update({'EstMeteoAfuera':meteoafuera})\n",
    "    dictt.update({'EstN30m':N30m})\n",
    "    dictt.update({'EstTto':Tto})\n",
    "    dictt.update({'URL Cuencas':url_cuencas})\n",
    "\n",
    "    #Se crea dataframe para guardar porque desde el Dic no sirve.\n",
    "    df=pd.DataFrame.from_dict(dictt)\n",
    "    #se guarda\n",
    "    if verbose:\n",
    "        try:\n",
    "            ruta_out=al.get_ruta(listconfig,'ruta_JSONinfosirenas')\n",
    "            df.to_json(ruta_out)\n",
    "            print 'Aviso: se crea JSON en '+ruta_out    \n",
    "        except:\n",
    "            print 'Aviso: no se crea JSON, revisar!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aviso: se crea JSON en /media/nicolas/Home/Jupyter/Soraya/git/Alarmas/04_web_hidrologia/hidrologia/results/01_estaticos/infosirenas.json\n"
     ]
    }
   ],
   "source": [
    "set_dfconfig2Json(rutaconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EstMeteoAdentro</th>\n",
       "      <th>EstMeteoAfuera</th>\n",
       "      <th>EstN30m</th>\n",
       "      <th>EstNivel</th>\n",
       "      <th>EstNivel1</th>\n",
       "      <th>EstPluvioAdentro</th>\n",
       "      <th>EstPluvioAfuera</th>\n",
       "      <th>EstTto</th>\n",
       "      <th>Nombres Alarmas</th>\n",
       "      <th>Nombres Corriente Asociada</th>\n",
       "      <th>URL Cuencas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>[197]</td>\n",
       "      <td>[249]</td>\n",
       "      <td>[108]</td>\n",
       "      <td>[90, 108]</td>\n",
       "      <td>[108]</td>\n",
       "      <td>[3, 18, 43]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SIRENA SANTA RITA SAN ANTONIO DE PRADO</td>\n",
       "      <td>Q. DONA MARIA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td></td>\n",
       "      <td>[249]</td>\n",
       "      <td></td>\n",
       "      <td>[173, 116]</td>\n",
       "      <td>[173]</td>\n",
       "      <td>[29]</td>\n",
       "      <td>[1, 8]</td>\n",
       "      <td></td>\n",
       "      <td>SIRENA BELEN - LAS VIOLETAS</td>\n",
       "      <td>Q. LA PICACHA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td></td>\n",
       "      <td>[249]</td>\n",
       "      <td></td>\n",
       "      <td>[173, 116]</td>\n",
       "      <td>[116]</td>\n",
       "      <td>[29]</td>\n",
       "      <td>[1, 8, 9]</td>\n",
       "      <td></td>\n",
       "      <td>SIRENA AGUAS FRIAS</td>\n",
       "      <td>Q. PICACHA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td></td>\n",
       "      <td>[105]</td>\n",
       "      <td></td>\n",
       "      <td>[259]</td>\n",
       "      <td>[259]</td>\n",
       "      <td></td>\n",
       "      <td>[33, 253]</td>\n",
       "      <td></td>\n",
       "      <td>SIRENA ANDALUCIA CALDAS</td>\n",
       "      <td>Q. LA CORRALA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td></td>\n",
       "      <td>[82]</td>\n",
       "      <td></td>\n",
       "      <td>[251, 186]</td>\n",
       "      <td>[186]</td>\n",
       "      <td></td>\n",
       "      <td>[234, 30]</td>\n",
       "      <td></td>\n",
       "      <td>SIRENA BARBOSA</td>\n",
       "      <td>Q. LA GALLINAZA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[265, 135]</td>\n",
       "      <td>[135]</td>\n",
       "      <td></td>\n",
       "      <td>[12, 14, 48, 89]</td>\n",
       "      <td></td>\n",
       "      <td>SIRENA BELLO CAFETAL</td>\n",
       "      <td>Q. LA LOCA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>[105]</td>\n",
       "      <td></td>\n",
       "      <td>[179, 106]</td>\n",
       "      <td>[179, 106, 124]</td>\n",
       "      <td>[106]</td>\n",
       "      <td>[267, 61, 261, 33, 253]</td>\n",
       "      <td></td>\n",
       "      <td>[179]</td>\n",
       "      <td>SIRENA LA ESTRELLA</td>\n",
       "      <td>RIO MEDELLIN - LA INMACULADA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td></td>\n",
       "      <td>[105]</td>\n",
       "      <td></td>\n",
       "      <td>[246]</td>\n",
       "      <td>[246]</td>\n",
       "      <td>[261]</td>\n",
       "      <td>[61]</td>\n",
       "      <td></td>\n",
       "      <td>SIRENA LA RAYA</td>\n",
       "      <td>Q. LA RAYA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td></td>\n",
       "      <td>[70]</td>\n",
       "      <td></td>\n",
       "      <td>[239]</td>\n",
       "      <td>[239]</td>\n",
       "      <td>[248]</td>\n",
       "      <td>[70]</td>\n",
       "      <td></td>\n",
       "      <td>SIRENA PIEDRAS BLANCAS</td>\n",
       "      <td>PIEDRAS BLANCAS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[283, 134]</td>\n",
       "      <td>[134]</td>\n",
       "      <td>[281, 121]</td>\n",
       "      <td>[89, 14, 48]</td>\n",
       "      <td></td>\n",
       "      <td>SIRENA LA ISLA</td>\n",
       "      <td>LA MADERA Y MONTANITA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[272]</td>\n",
       "      <td>[272]</td>\n",
       "      <td></td>\n",
       "      <td>[88, 31]</td>\n",
       "      <td></td>\n",
       "      <td>SIRENA EL SALADO - JAMUNDI</td>\n",
       "      <td>EL SALADO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[37, 74]</td>\n",
       "      <td></td>\n",
       "      <td>SIRENA LA AVELINA</td>\n",
       "      <td>LA GARCIA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[155]</td>\n",
       "      <td>[155]</td>\n",
       "      <td></td>\n",
       "      <td>[37, 74]</td>\n",
       "      <td></td>\n",
       "      <td>EL HATO</td>\n",
       "      <td>EL HATO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    EstMeteoAdentro EstMeteoAfuera     EstN30m         EstNivel EstNivel1  \\\n",
       "216           [197]          [249]       [108]        [90, 108]     [108]   \n",
       "219                          [249]                   [173, 116]     [173]   \n",
       "220                          [249]                   [173, 116]     [116]   \n",
       "221                          [105]                        [259]     [259]   \n",
       "222                           [82]                   [251, 186]     [186]   \n",
       "223                                                  [265, 135]     [135]   \n",
       "224           [105]                 [179, 106]  [179, 106, 124]     [106]   \n",
       "226                          [105]                        [246]     [246]   \n",
       "279                           [70]                        [239]     [239]   \n",
       "280                                                  [283, 134]     [134]   \n",
       "285                                                       [272]     [272]   \n",
       "300                                                                         \n",
       "301                                                       [155]     [155]   \n",
       "\n",
       "            EstPluvioAdentro   EstPluvioAfuera EstTto  \\\n",
       "216              [3, 18, 43]                            \n",
       "219                     [29]            [1, 8]          \n",
       "220                     [29]         [1, 8, 9]          \n",
       "221                                  [33, 253]          \n",
       "222                                  [234, 30]          \n",
       "223                           [12, 14, 48, 89]          \n",
       "224  [267, 61, 261, 33, 253]                    [179]   \n",
       "226                    [261]              [61]          \n",
       "279                    [248]              [70]          \n",
       "280               [281, 121]      [89, 14, 48]          \n",
       "285                                   [88, 31]          \n",
       "300                                   [37, 74]          \n",
       "301                                   [37, 74]          \n",
       "\n",
       "                            Nombres Alarmas    Nombres Corriente Asociada  \\\n",
       "216  SIRENA SANTA RITA SAN ANTONIO DE PRADO                 Q. DONA MARIA   \n",
       "219             SIRENA BELEN - LAS VIOLETAS                 Q. LA PICACHA   \n",
       "220                      SIRENA AGUAS FRIAS                    Q. PICACHA   \n",
       "221                 SIRENA ANDALUCIA CALDAS                 Q. LA CORRALA   \n",
       "222                          SIRENA BARBOSA               Q. LA GALLINAZA   \n",
       "223                    SIRENA BELLO CAFETAL                    Q. LA LOCA   \n",
       "224                      SIRENA LA ESTRELLA  RIO MEDELLIN - LA INMACULADA   \n",
       "226                          SIRENA LA RAYA                    Q. LA RAYA   \n",
       "279                  SIRENA PIEDRAS BLANCAS               PIEDRAS BLANCAS   \n",
       "280                          SIRENA LA ISLA         LA MADERA Y MONTANITA   \n",
       "285              SIRENA EL SALADO - JAMUNDI                     EL SALADO   \n",
       "300                       SIRENA LA AVELINA                     LA GARCIA   \n",
       "301                                EL HATO                        EL HATO   \n",
       "\n",
       "     URL Cuencas  \n",
       "216          NaN  \n",
       "219          NaN  \n",
       "220          NaN  \n",
       "221          NaN  \n",
       "222          NaN  \n",
       "223          NaN  \n",
       "224          NaN  \n",
       "226          NaN  \n",
       "279          NaN  \n",
       "280          NaN  \n",
       "285          NaN  \n",
       "300          NaN  \n",
       "301          NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfconfig=pd.read_json(al.get_ruta(listconfig,'ruta_JSONinfosirenas'))\n",
    "dfconfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diccionario variable - nivel\n",
    "\n",
    "- **Fecha y Hora**\n",
    "- **N actual** Se consulta a la base de datos en 192.168.1.74 usando el modulo CPR.\n",
    "- **Nombre riesgo actual** - Se consulta de un binario que se debe actualizar cuando hayan nuevas estaciones.\n",
    "                        '../series/op/risklevels_all_op.msg'\n",
    "- **Color riesgo actual**\n",
    "- **Nmáx 30 min**  - Se consulta del modelo de Esneider, se cogen las estaciones quehayan.\n",
    "- **Nombre riesgo 30min**\n",
    "- **Color**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notas**:\n",
    "\n",
    "- Siempre se lee el último nivel del .csv de mario, si la estación no tiene datos el programa se queda leyendo  el último registrado.\n",
    "\n",
    "¿Mario que hace con los faltantes?¿nan?\n",
    "\n",
    "- Si es nan, todos los campos son nan y el color es gris.\n",
    "\n",
    "- ** la estaciones en est_n_alarmas deben estar incluídas en est_n**\n",
    "\n",
    "- ** las de est_pronos_al deben estar en n_pronos**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qué y cuándo se debe actualizar:\n",
    "\n",
    "- se instale nuevas estaciones de nivel para alarmas! -> agregar a n_alarmas, actualizar '../series/op/estaciones_datos_op.msg'\n",
    "- se cambien los niveles de alerta de las estaciones! -> '../series/op/risklevels_all_op.msg'\n",
    "- cuando se agreguen estaciones de nivel de alarmas al modelo estadístico -> n_pronos_alarmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nivel Actual + irisk levels + N30m + risk levels 30m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_levelrisk(listconfig,dfconfig,risklevels_all):\n",
    "    n_alarmas=np.unique(np.sort(np.hstack(dfconfig['EstNivel'])))###########ASIGNACION DE ESTACIONES.\n",
    "\n",
    "    ### inputs para risk_actual\n",
    "    risk_names=al.get_line(listconfig,'risk_names')#['Level Action', 'Minor Flood', 'Moderate Flood','Major Flood','Major to the major!']\n",
    "    risk_colors=al.get_line(listconfig,'risk_colors')#['#008000','#FFA500','#FF4500','#4B0082','#4B0082']\n",
    "    #se leen los niveles de riesgo\n",
    "#     risklevels_all=pd.read_csv(al.get_ruta(listconfig,'ruta_allrisklevels'))###################################\n",
    "\n",
    "    #for para todos las estaciones\n",
    "    n_act={};risk_act={};riskcolor_act={}\n",
    "    for est in n_alarmas:\n",
    "        #se obtiene guarda el n_act.\n",
    "        self= cpr.Nivel(est)\n",
    "        start=dt.datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "        end=dt.datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "        level=self.get_level(start,end,offset='dinamico')['nivel']\n",
    "        n_act.update({str(est):float(level.values)})    \n",
    "        #si es nan\n",
    "        if np.isnan(level[level.index[0]]):\n",
    "            risk_act.update({str(est):'nan'})\n",
    "            riskcolor_act.update({str(est):'#A9A9A9'})\n",
    "        #si no, se obtiene el risk actual.\n",
    "        else:\n",
    "            #se leen los risklevels de la estacion y se hace lista\n",
    "            rl_list=list(np.array(risklevels_all.loc[risklevels_all.index==est])[0])\n",
    "            #se le agrega el n_actual   \n",
    "            rl_list.append(n_act[str(est)])\n",
    "            #se organiza de menor a mayor\n",
    "            rl_ordered=np.argsort(rl_list)\n",
    "            #en que posicion quedo el ultimo valor agregado a la lista -> risk\n",
    "            risk=int(np.where(rl_ordered==4)[0])\n",
    "            #se guarda en el dic\n",
    "            risk_act.update({str(est):risk_names[risk]})\n",
    "            riskcolor_act.update({str(est):risk_colors[risk]})\n",
    "\n",
    "    #### Nivel 30m\n",
    "    ### inputs para N30m\n",
    "    #--------------------------\n",
    "    # se lee la info del pronostico 30m\n",
    "    # ruta_npronos='/media/nicolas/Home/Jupyter/Esneider/modelo_crecidas/pronostico_niveles.bin'\n",
    "    f=open(al.get_ruta(listconfig,'ruta_estadistico'))\n",
    "    n_pronos=pickle.load(f)\n",
    "    f.close()\n",
    "    n_pronos=pd.DataFrame(n_pronos)\n",
    "    #se lee la info de dfconfig\n",
    "    n_pronos_alarmas=np.hstack(dfconfig['EstN30m'])\n",
    "    #se leen las \n",
    "    n_pronos_alarmas=map(int,n_pronos_alarmas[np.where(n_pronos_alarmas)[0]])\n",
    "    est_pronos_ordered=np.sort(n_pronos[0])\n",
    "    #pos de alarmas en n_pronos\n",
    "    pos_pronos_al=est_pronos_ordered.searchsorted(n_pronos_alarmas)\n",
    "\n",
    "    #todas las estaciones.\n",
    "    n_pronostico={};risk_pronos={};riskcolor_pronos={}\n",
    "    for pos_pronos_est in pos_pronos_al:\n",
    "        #filas en n_pronos que concuerdan con alarmas}\n",
    "        pro=n_pronos.loc[n_pronos[0]==est_pronos_ordered[pos_pronos_est]]\n",
    "        #se obtiene y guarda el n_pronos.\n",
    "        pronos_list=[float(x)for x in np.array(pro)[0][1:]]\n",
    "        pronos=pronos_list[2]\n",
    "        n_pronostico.update({str(est_pronos_ordered[pos_pronos_est]):pronos})\n",
    "\n",
    "        #si es nan - por algun motivo razon o circunstacia.\n",
    "        if np.isnan(pronos):\n",
    "            risk_pronos.update({str(est_pronos_ordered[pos_pronos_est]):'nan'})\n",
    "            riskcolor_pronos.update({str(est_pronos_ordered[pos_pronos_est]):'#A9A9A9'})\n",
    "        else:\n",
    "            #se obtiene el risk_actual\n",
    "#             rl_=risklevels_all.loc[risklevels_all['codigo']==est_pronos_ordered[pos_pronos_est]]\n",
    "\n",
    "            #lista obviando la col='codigo'\n",
    "#             rl_list=[float(x)for x in np.array(rl)[0][2:]]\n",
    "            rl_list=list(np.array(risklevels_all.loc[risklevels_all.index==est_pronos_ordered[pos_pronos_est]])[0])\n",
    "            #se le agrega el n_actual   \n",
    "            rl_list.append(pronos)\n",
    "            #se organiza de menor a mayor\n",
    "            rl_ordered=np.argsort(rl_list)\n",
    "            #en que posicion quedo -> risk\n",
    "            risk=int(np.where(rl_ordered==4)[0])\n",
    "            #se guarda en el dic\n",
    "            risk_pronos.update({str(est_pronos_ordered[pos_pronos_est]):risk_names[risk]})\n",
    "            riskcolor_pronos.update({str(est_pronos_ordered[pos_pronos_est]):risk_colors[risk]})\n",
    "\n",
    "    #Escribe diccionario para json\n",
    "    dictt={}\n",
    "    #Datetime en formato '%Y-%m-%d-%H:%M'\n",
    "    dictt.update({'Fecha y Hora':str(level.index[0])})\n",
    "    dictt.update({'Nivel Actual':n_act})\n",
    "    dictt.update({'Riesgo Actual':risk_act})\n",
    "    dictt.update({'Color Riesgo Actual':riskcolor_act})\n",
    "    dictt.update({'Nivel Max. prox. 30min':n_pronostico})\n",
    "    dictt.update({'Riesgo Max. prox. 30min':risk_pronos})\n",
    "    dictt.update({'Color Riesgo Max. prox. 30min':riskcolor_pronos})\n",
    "\n",
    "    #Escribe json\n",
    "    df=pd.DataFrame.from_dict(dictt)\n",
    "    df.to_json(al.get_ruta(listconfig,'ruta_JSONnivel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_levelrisk(listconfig,dfconfig,risklevels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color Riesgo Actual</th>\n",
       "      <th>Color Riesgo Max. prax. 30min</th>\n",
       "      <th>Fecha y Hora</th>\n",
       "      <th>Nivel Actual</th>\n",
       "      <th>Nivel Max. prax. 30min</th>\n",
       "      <th>Riesgo Actual</th>\n",
       "      <th>Riesgo Max. prax. 30min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>#008000</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-02-11 21:00:00</td>\n",
       "      <td>29.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LevelAction</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>None</td>\n",
       "      <td>#008000</td>\n",
       "      <td>2018-02-11 21:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>LevelAction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>#008000</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-02-11 21:00:00</td>\n",
       "      <td>68.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LevelAction</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>None</td>\n",
       "      <td>#008000</td>\n",
       "      <td>2018-02-11 21:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>LevelAction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>#008000</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-02-11 21:00:00</td>\n",
       "      <td>26.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LevelAction</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>#A9A9A9</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-02-11 21:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>#A9A9A9</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-02-11 21:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>None</td>\n",
       "      <td>#008000</td>\n",
       "      <td>2018-02-11 21:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>LevelAction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>#008000</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-02-11 21:00:00</td>\n",
       "      <td>24.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LevelAction</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>#A9A9A9</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-02-11 21:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>#008000</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-02-11 21:00:00</td>\n",
       "      <td>15.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LevelAction</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>#008000</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-02-11 21:00:00</td>\n",
       "      <td>3.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LevelAction</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>#008000</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-02-11 21:00:00</td>\n",
       "      <td>22.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LevelAction</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>#008000</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-02-11 21:00:00</td>\n",
       "      <td>71.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LevelAction</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Color Riesgo Actual Color Riesgo Max. prax. 30min         Fecha y Hora  \\\n",
       "106             #008000                          None  2018-02-11 21:00:00   \n",
       "106                None                       #008000  2018-02-11 21:00:00   \n",
       "108             #008000                          None  2018-02-11 21:00:00   \n",
       "108                None                       #008000  2018-02-11 21:00:00   \n",
       "124             #008000                          None  2018-02-11 21:00:00   \n",
       "173             #A9A9A9                          None  2018-02-11 21:00:00   \n",
       "179             #A9A9A9                          None  2018-02-11 21:00:00   \n",
       "179                None                       #008000  2018-02-11 21:00:00   \n",
       "186             #008000                          None  2018-02-11 21:00:00   \n",
       "246             #A9A9A9                          None  2018-02-11 21:00:00   \n",
       "251             #008000                          None  2018-02-11 21:00:00   \n",
       "259             #008000                          None  2018-02-11 21:00:00   \n",
       "265             #008000                          None  2018-02-11 21:00:00   \n",
       "90              #008000                          None  2018-02-11 21:00:00   \n",
       "\n",
       "     Nivel Actual  Nivel Max. prax. 30min Riesgo Actual  \\\n",
       "106         29.23                     NaN   LevelAction   \n",
       "106           NaN                     0.0          None   \n",
       "108         68.97                     NaN   LevelAction   \n",
       "108           NaN                     0.0          None   \n",
       "124         26.28                     NaN   LevelAction   \n",
       "173           NaN                     NaN           nan   \n",
       "179           NaN                     NaN           nan   \n",
       "179           NaN                     0.0          None   \n",
       "186         24.42                     NaN   LevelAction   \n",
       "246           NaN                     NaN           nan   \n",
       "251         15.66                     NaN   LevelAction   \n",
       "259          3.38                     NaN   LevelAction   \n",
       "265         22.39                     NaN   LevelAction   \n",
       "90          71.98                     NaN   LevelAction   \n",
       "\n",
       "    Riesgo Max. prax. 30min  \n",
       "106                    None  \n",
       "106             LevelAction  \n",
       "108                    None  \n",
       "108             LevelAction  \n",
       "124                    None  \n",
       "173                    None  \n",
       "179                    None  \n",
       "179             LevelAction  \n",
       "186                    None  \n",
       "246                    None  \n",
       "251                    None  \n",
       "259                    None  \n",
       "265                    None  \n",
       "90                     None  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Lee Json\n",
    "pd.read_json(al.get_ruta(listconfig,'ruta_JSONnivel'))\n",
    "#!!!! La info del N30m se lee en la segunda de las uqe tienen repetidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Color Riesgo Actual': {'106': '#008000',\n",
       "  '108': '#008000',\n",
       "  '124': '#008000',\n",
       "  '173': '#A9A9A9',\n",
       "  '179': '#A9A9A9',\n",
       "  '186': '#008000',\n",
       "  '246': '#A9A9A9',\n",
       "  '251': '#008000',\n",
       "  '259': '#008000',\n",
       "  '265': '#008000',\n",
       "  '90': '#008000'},\n",
       " 'Color Riesgo Max. prax. 30min': {'106.0': '#008000',\n",
       "  '108.0': '#008000',\n",
       "  '179.0': '#008000'},\n",
       " 'Fecha y Hora': '2018-02-11 20:55:00',\n",
       " 'Nivel Actual': {'106': 29.970000000000027,\n",
       "  '108': 69.29000000000002,\n",
       "  '124': 25.379999999999995,\n",
       "  '173': nan,\n",
       "  '179': nan,\n",
       "  '186': 24.55000000000001,\n",
       "  '246': nan,\n",
       "  '251': 15.530000000000001,\n",
       "  '259': 3.4399999999999977,\n",
       "  '265': 22.00999999999999,\n",
       "  '90': 71.92000000000002},\n",
       " 'Nivel Max. prax. 30min': {'106.0': 0.0, '108.0': 0.0, '179.0': 0.0},\n",
       " 'Riesgo Actual': {'106': 'LevelAction',\n",
       "  '108': 'LevelAction',\n",
       "  '124': 'LevelAction',\n",
       "  '173': 'nan',\n",
       "  '179': 'nan',\n",
       "  '186': 'LevelAction',\n",
       "  '246': 'nan',\n",
       "  '251': 'LevelAction',\n",
       "  '259': 'LevelAction',\n",
       "  '265': 'LevelAction',\n",
       "  '90': 'LevelAction'},\n",
       " 'Riesgo Max. prax. 30min': {'106.0': 'LevelAction',\n",
       "  '108.0': 'LevelAction',\n",
       "  '179.0': 'LevelAction'}}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pluvio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pluviorisk(listconfig,dfconfig):\n",
    "    # estaciones pluvio\n",
    "    est_p=np.sort(np.hstack(dfconfig['EstMeteoAdentro']))\n",
    "    est_p=map(int,est_p[np.where(est_p)[0]])\n",
    "    est_p1=np.sort(np.hstack(dfconfig['EstMeteoAfuera']))\n",
    "    est_p.append(map(int,est_p1[np.where(est_p1)[0]]))\n",
    "    est_p2=np.sort(np.hstack(dfconfig['EstPluvioAdentro']))\n",
    "    est_p.append(map(int,est_p2[np.where(est_p2)[0]]))\n",
    "    est_p3=np.sort(np.hstack(dfconfig['EstPluvioAfuera']))\n",
    "    est_p.append(map(int,est_p3[np.where(est_p3)[0]]))\n",
    "    # forecast\n",
    "    res_pluvioforecast=al.get_ruta(listconfig,'ruta_pluvioforecast')\n",
    "    #Se lee forecast estadistico escenario medio.\n",
    "    f = open(res_pluvioforecast+'_cast_normal.rain','r')\n",
    "    cast_normal = pickle.load(f)\n",
    "    f.close()\n",
    "    # est pluvio_forecast\n",
    "    est_pluvio=map(str,np.unique(np.hstack(est_p)))\n",
    "    p_out=[i in cast_normal.columns for i in est_pluvio]\n",
    "    p_in=np.where(p_out)[0]\n",
    "    est_pluvio=np.take(est_pluvio,p_in)\n",
    "    #df pluvioforecast con estaciones de alarmas\n",
    "    df_p60m=cast_normal[est_pluvio]\n",
    "    ##Iteracion\n",
    "    p_act={};p60m={};p60m_time={}\n",
    "    for est in np.unique(np.hstack(est_p)):\n",
    "        #se obtiene y guardar pluvio actual\n",
    "        self= cpr.Pluvio(est)\n",
    "        start=dt.datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "        end=dt.datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "        pluvio=self.read_pluvio(start,end)\n",
    "        p_act.update({str(est):float(pluvio.values)})\n",
    "        #se obtiene y guarda el maximo de pluvio en la proxima hora.\n",
    "        if str(est) in est_pluvio:\n",
    "            p60m.update({str(est):df_p60m[str(est)].max()})\n",
    "            p60m_time.update({str(est):str(df_p60m[str(est)].argmax())})\n",
    "            \n",
    "    #Escribe diccionario para json\n",
    "    dictt={}\n",
    "    #Datetime en formato '%Y-%m-%d-%H:%M'\n",
    "    dictt.update({'Fecha y Hora':str(pluvio.index[0])})\n",
    "    dictt.update({'Pluvio Actual':p_act})\n",
    "    dictt.update({'Pluvio max. prox. 60  min':p60m})\n",
    "    dictt.update({'Hora máx. prox. 60  min':p60m_time})\n",
    "    \n",
    "    #Escribe json\n",
    "    df=pd.DataFrame.from_dict(dictt)\n",
    "    df.to_json(al.get_ruta(listconfig,'ruta_JSONpluvio'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No data found for station << Escuela Rural Yarumalito - 3 >>, output will be a DataFrame filled with NaN\n",
      "Warning: No data found for station << Santa Maria Goretti - 33 >>, output will be a DataFrame filled with NaN\n",
      "Warning: No data found for station << Escuela Rural Quebrada Larga - 43 >>, output will be a DataFrame filled with NaN\n",
      "Warning: No data found for station << I.E Manuel Jose Caicedo - 82 >>, output will be a DataFrame filled with NaN\n",
      "Warning: No data found for station << Parque 3 Aguas - 105 >>, output will be a DataFrame filled with NaN\n",
      "Warning: No data found for station << Universidad de Medellin - Meteorologia - 197 >>, output will be a DataFrame filled with NaN\n",
      "Warning: No data found for station << Escuela CEDEPRO - 249 >>, output will be a DataFrame filled with NaN\n",
      "Warning: No data found for station << Deslizamiento La raya - Pluviografica - 261 >>, output will be a DataFrame filled with NaN\n"
     ]
    }
   ],
   "source": [
    "get_pluviorisk(listconfig,dfconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha y Hora</th>\n",
       "      <th>Hora máx. prox. 60  min</th>\n",
       "      <th>Pluvio Actual</th>\n",
       "      <th>Pluvio max. prox. 60  min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2018-02-11 23:10:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Fecha y Hora Hora máx. prox. 60  min  Pluvio Actual  \\\n",
       "105  2018-02-11 23:10:00                    None            NaN   \n",
       "18   2018-02-11 23:10:00     2018-02-11 23:10:00            0.0   \n",
       "197  2018-02-11 23:10:00                    None            NaN   \n",
       "249  2018-02-11 23:10:00                    None            NaN   \n",
       "253  2018-02-11 23:10:00     2018-02-11 23:10:00            0.0   \n",
       "261  2018-02-11 23:10:00     2018-02-11 23:10:00            NaN   \n",
       "267  2018-02-11 23:10:00     2018-02-11 23:10:00            0.0   \n",
       "29   2018-02-11 23:10:00     2018-02-11 23:10:00            0.0   \n",
       "3    2018-02-11 23:10:00     2018-02-11 23:10:00            NaN   \n",
       "33   2018-02-11 23:10:00     2018-02-11 23:10:00            NaN   \n",
       "43   2018-02-11 23:10:00     2018-02-11 23:10:00            NaN   \n",
       "61   2018-02-11 23:10:00     2018-02-11 23:10:00            0.0   \n",
       "82   2018-02-11 23:10:00                    None            NaN   \n",
       "\n",
       "     Pluvio max. prox. 60  min  \n",
       "105                        NaN  \n",
       "18                         0.0  \n",
       "197                        NaN  \n",
       "249                        NaN  \n",
       "253                        0.0  \n",
       "261                        0.0  \n",
       "267                        0.0  \n",
       "29                         0.0  \n",
       "3                          0.0  \n",
       "33                         0.0  \n",
       "43                         0.0  \n",
       "61                         0.0  \n",
       "82                         NaN  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Lee Json\n",
    "pd.read_json(al.get_ruta(listconfig,'ruta_JSONpluvio'))\n",
    "#!!!! Las estaciones que no tienen info del P60m son las que tienen NaN y en hora None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GeoJSONs Pluvio-Nivel\n",
    "Funcion que escriben GeoJsons de puntos que serán estáticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeGeoJSON_points(rutaconfig,dfconfig_key,verbose=True):\n",
    "    #INPUTS\n",
    "    #lee configfile\n",
    "    listconfig=al.get_rutesList(rutaconfig)\n",
    "    #dfconfig\n",
    "    dfconfig=pd.read_json(al.get_ruta(listconfig,'ruta_JSONinfosirenas'))\n",
    "    #Estaciones.\n",
    "    if dfconfig_key== 'EstNivel': #para que consulte las cosas de NIVEL\n",
    "        #rutas\n",
    "        rutaJSON=al.get_ruta(listconfig,'ruta_JSONnivel')\n",
    "        rutaGeoJSON=al.get_ruta(listconfig,'ruta_GeoJSONnivel')\n",
    "        #consulta a BD SIATA de la info de tabla estaciones para red='nivel'.\n",
    "        infoestaciones = cpr.Nivel().infost\n",
    "        #estaciones\n",
    "        estaciones=np.sort(np.hstack(dfconfig[dfconfig_key]))\n",
    "        estaciones=map(int,estaciones[np.where(estaciones)[0]])\n",
    "    else: #para que consulte las cosas de PLUVIO\n",
    "        #rutas\n",
    "        rutaJSON=al.get_ruta(listconfig,'ruta_JSONpluvio')\n",
    "        rutaGeoJSON=al.get_ruta(listconfig,'ruta_GeoJSONpluvio')\n",
    "        #consulta a BD SIATA de la info de tabla estaciones para red='pluvio'.\n",
    "        infoestaciones = cpr.Pluvio().infost\n",
    "        # se definen estaciones\n",
    "    #     est_p=np.sort(np.hstack(dfconfig['EstMeteoAdentro']))\n",
    "    #     est_p=map(int,est_p[np.where(est_p)[0]])\n",
    "    #     est_p1=np.sort(np.hstack(dfconfig['EstMeteoAfuera']))\n",
    "    #     est_p.append(map(int,est_p1[np.where(est_p1)[0]]))\n",
    "        est_p2=np.sort(np.hstack(dfconfig['EstPluvioAdentro']))\n",
    "        est_p=map(int,est_p2[np.where(est_p2)[0]])\n",
    "        est_p3=np.sort(np.hstack(dfconfig['EstPluvioAfuera']))\n",
    "        est_p.append(map(int,est_p3[np.where(est_p3)[0]]))\n",
    "        estaciones=map(str,np.unique(np.hstack(est_p)))        \n",
    "\n",
    "    #GEOJSON.\n",
    "    #propiedades estacion\n",
    "    features=[]\n",
    "    for est in estaciones:\n",
    "        properties={\n",
    "                \"Codigo\":str(est),\n",
    "                \"Nombre\":infoestaciones['NombreEstacion'][infoestaciones.index==est][est],\n",
    "                \"Ciudad\":infoestaciones['Ciudad'][infoestaciones.index==est][est],\n",
    "                \"jsondata\":rutaJSON           \n",
    "                }\n",
    "        geometry={\"type\":\"Point\",\"coordinates\":[float(infoestaciones['Longitude'][infoestaciones.index==est][est]),float(infoestaciones['Latitude'][infoestaciones.index==est][est])]\n",
    "                }\n",
    "        feat_est={}\n",
    "        feat_est.update({\"type\":\"Feature\"})\n",
    "        feat_est.update({\"geometry\":geometry})\n",
    "        feat_est.update({\"properties\":properties})\n",
    "        #se van guardando para todas las estaciones.\n",
    "        features.append(feat_est)\n",
    "    dicGeoJSON={}\n",
    "    dicGeoJSON.update({\"features\":features})\n",
    "    dicGeoJSON.update({\"type\":\"FeatureCollection\"})\n",
    "\n",
    "    #Escribe GeoJSON incial\n",
    "    f = open(rutaGeoJSON,'w')\n",
    "    f.write(str(dicGeoJSON))\n",
    "    f.close()\n",
    "    #lo lee de nuevo para poder aplicar replace.\n",
    "    f = open(rutaGeoJSON,'r')\n",
    "    filedata = f.read()\n",
    "    f.close()\n",
    "    #replace de comilla sencilla a doble para que pueda servir el GeoJSON\n",
    "    newdata = filedata.replace(\"'\",'\"')\n",
    "    #escribe nuevamente\n",
    "    f = open(rutaGeoJSON,'w')\n",
    "    f.write(newdata)\n",
    "    f.close()\n",
    "    \n",
    "    if verbose:\n",
    "        print 'Aviso: Se genera archivo de puntos GeoJSON en '+rutaGeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aviso: Se genera archivo de puntos GeoJSON en /media/nicolas/Home/Jupyter/Soraya/git/Alarmas/04_web_hidrologia/hidrologia/results/01_estaticos/Geo_nivel.geojson\n"
     ]
    }
   ],
   "source": [
    "writeGeoJSON_points(rutaconfig,'EstNivel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### KMLs Pluvio-Nivel\n",
    "Funcion que escriben KML de puntos que serán estáticos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write KML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data={}\n",
    "for est in estaciones:\n",
    "    Data_est={}\n",
    "#     Data_est.update({FieldsNames[0]:infoestaciones['NombreEstacion'][infoestaciones.index==est][est]})\n",
    "    Data_est.update({FieldsNames[0]:str(est)})\n",
    "    Data_est.update({FieldsNames[1]:infoestaciones['Ciudad'][infoestaciones.index==est][est]})\n",
    "    Data_est.update({FieldsNames[2]:str(np.array(jsonnivel[jsonnivel.index==est]['Nivel Actual'])[0])})\n",
    "    Data.update({str(est):Data_est})\n",
    "Data.update({FieldsNames[3]:str(jsonnivel[jsonnivel.index==estaciones[0]]['Fecha y Hora'][estaciones[0]])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeKML(listconfig,dfconfig_key,verbose=True):\n",
    "    ''' Escribe '''\n",
    "    #dfconfig\n",
    "    dfconfig=pd.read_json(al.get_ruta(listconfig,'ruta_JSONinfosirenas'))\n",
    "    #Estaciones.\n",
    "    if dfconfig_key== 'EstNivel': #para que consulte las cosas de NIVEL\n",
    "        #rutas\n",
    "        rutaJSON=al.get_ruta(listconfig,'ruta_JSONnivel')\n",
    "        rutaKML=al.get_ruta(listconfig,'ruta_KMLnivel')\n",
    "        #consulta a BD SIATA de la info de tabla estaciones para red='nivel'.\n",
    "        infoestaciones = cpr.Nivel().infost\n",
    "        #estaciones\n",
    "        estaciones=np.sort(np.hstack(dfconfig[dfconfig_key]))\n",
    "        estaciones=map(int,estaciones[np.where(estaciones)[0]])\n",
    "        #Alista datos para KML - NIVEL\n",
    "        JSON=pd.read_json(rutaJSON)\n",
    "        #Campos a agregar a KML - NIVEL.\n",
    "        FieldsNames=['Codigo','Ciudad','Nact','fecha_act']\n",
    "        FieldsTypes=['string','string','string','string']\n",
    "        SchemaName='RedNivel'\n",
    "        #datos\n",
    "        Data={}\n",
    "        for est in estaciones:\n",
    "            Data_est={}\n",
    "            Data_est.update({FieldsNames[0]:str(est)})\n",
    "            Data_est.update({FieldsNames[1]:infoestaciones['Ciudad'][infoestaciones.index==est][est]})\n",
    "            Data_est.update({FieldsNames[2]:str(np.array(JSON[JSON.index==est]['Nivel Actual'])[0])})\n",
    "            Data.update({str(est):Data_est})\n",
    "        Data.update({FieldsNames[3]:str(JSON[JSON.index==estaciones[0]]['Fecha y Hora'][estaciones[0]])})\n",
    "    else: #para que consulte las cosas de PLUVIO\n",
    "        #rutas\n",
    "        rutaJSON=al.get_ruta(listconfig,'ruta_JSONpluvio')\n",
    "        rutaKML=al.get_ruta(listconfig,'ruta_KMLpluvio')\n",
    "        #consulta a BD SIATA de la info de tabla estaciones para red='pluvio'.\n",
    "        infoestaciones = cpr.Pluvio().infost\n",
    "        # se definen estaciones\n",
    "    #     est_p=np.sort(np.hstack(dfconfig['EstMeteoAdentro']))\n",
    "    #     est_p=map(int,est_p[np.where(est_p)[0]])\n",
    "    #     est_p1=np.sort(np.hstack(dfconfig['EstMeteoAfuera']))\n",
    "    #     est_p.append(map(int,est_p1[np.where(est_p1)[0]]))\n",
    "        est_p2=np.sort(np.hstack(dfconfig['EstPluvioAdentro']))\n",
    "        est_p=map(int,est_p2[np.where(est_p2)[0]])\n",
    "        est_p3=np.sort(np.hstack(dfconfig['EstPluvioAfuera']))\n",
    "        est_p.append(map(int,est_p3[np.where(est_p3)[0]]))\n",
    "        estaciones=map(str,np.unique(np.hstack(est_p))) \n",
    "    \n",
    "\n",
    "    #KML\n",
    "    #BEGINNING\n",
    "    KML=['<?xml version=\"1.0\" encoding=\"utf-8\" ?>\\n',\n",
    "     '<kml xmlns=\"http://www.opengis.net/kml/2.2\">\\n',\n",
    "     '<Document id=\"root_doc\">\\n']\n",
    "    #SCHEMA\n",
    "    KML.append('<Schema name=\"'+SchemaName+'\" id=\"'+SchemaName+'\">\\n')\n",
    "    for index,Fname in enumerate(FieldsNames):\n",
    "        KML.append('  <SimpleField name=\"'+Fname+'\" type=\"'+FieldsTypes[index]+'\"></SimpleField>\\n')\n",
    "    KML.append('</Schema>\\n')\n",
    "    #FOLDER\n",
    "    KML.append('<Folder><name>'+SchemaName+'</name>\\n')\n",
    "    #PLACEMARKS\n",
    "    PlmkNames=[infoestaciones['NombreEstacion'][infoestaciones.index==est][est] for est in estaciones]\n",
    "    for index,est in enumerate(estaciones):\n",
    "        KML.append('  <Placemark>\\n')\n",
    "\n",
    "        KML.append('<name>\"'+PlmkNames[index]+'\"</name>\\n')\n",
    "        KML.append('    <ExtendedData><SchemaData schemaUrl=\"#RedAirePM25\">\\n')\n",
    "        #itera sobre campos agregados\n",
    "        for Fname in (FieldsNames[:-1]):\n",
    "            KML.append('        <SimpleData name=\"'+Fname+'\">'+Data[str(est)][Fname]+'</SimpleData>\\n')\n",
    "        KML.append('    </SchemaData></ExtendedData>\\n')\n",
    "        KML.append('      <Point><coordinates>'+infoestaciones['Longitude'][infoestaciones.index==est][est]+','+infoestaciones['Latitude'][infoestaciones.index==est][est]+'</coordinates></Point>\\n')\n",
    "        KML.append('  </Placemark>\\n')  \n",
    "    #CLOSING\n",
    "    KML.append('</Folder>\\n')\n",
    "    KML.append('</Document></kml>')\n",
    "    \n",
    "    #WRITE FILE!\n",
    "    f = open(rutaKML,'w')\n",
    "    f.writelines(KML)\n",
    "    f.close()\n",
    "    \n",
    "    if verbose:\n",
    "        print 'Aviso: Se genera archivo de puntos KML en '+rutaKML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aviso: Se genera archivo de puntos KML en /media/nicolas/Home/Jupyter/Soraya/git/Alarmas/04_web_hidrologia/hidrologia/results/02_operacionales/nivel.kml\n"
     ]
    }
   ],
   "source": [
    " writeKML(listconfig,dfconfig_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MONTAR TODAS LOS .nc DE LAS CUENCAS Y CRONEAR LA LLUVIA!... SACARLAS DE DONDE LOS GENERA MARIO A PARTIR DEL UMBRAL DE NIVEL.\n",
    "\n",
    "REVISAR OTRAS GRÁFICAS QUE SE HABÍAN CONVERSADO CON ESNEIDER PARA MONTAR ACÁ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Niveles de riesgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# codigo de la estacion.\n",
    "codeest=est_n_ordered[0]\n",
    "# coneccion a bd con usuario operacional\n",
    "host   = '192.168.1.74'\n",
    "user   = 'siata_Oper'\n",
    "passwd = 'si@t@64512_operacional'\n",
    "bd     = 'siata'\n",
    "#Consulta a tabla estaciones\n",
    "Estaciones=\"SELECT codigo,action_level,minor_flooding,moderate_flooding,major_flooding  FROM estaciones WHERE codigo=(\"+str(codeest)+\")\"\n",
    "dbconn = MySQLdb.connect(host, user,passwd,bd)\n",
    "db_cursor = dbconn.cursor()\n",
    "db_cursor.execute(Estaciones)\n",
    "result = np.array(db_cursor.fetchall())\n",
    "#holding\n",
    "risklevels_all=pd.DataFrame(result,columns=['codigo','action_level','minor_f','moderate_f','major_f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo</th>\n",
       "      <th>action_level</th>\n",
       "      <th>minor_f</th>\n",
       "      <th>moderate_f</th>\n",
       "      <th>major_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>93.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>259.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  codigo action_level minor_f moderate_f major_f\n",
       "0     90         93.0   171.0      202.0   259.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risklevels_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ind,est in enumerate(est_n_ordered):\n",
    "    try:\n",
    "        # codigo de la estacion.\n",
    "        codeest=est_n_ordered[ind+1]\n",
    "        # coneccion a bd con usuario operacional\n",
    "        host   = '192.168.1.74'\n",
    "        user   = 'siata_Oper'\n",
    "        passwd = 'si@t@64512_operacional'\n",
    "        bd     = 'siata'\n",
    "        #Consulta a tabla estaciones\n",
    "        Estaciones=\"SELECT codigo,action_level,minor_flooding,moderate_flooding,major_flooding  FROM estaciones WHERE codigo=(\"+str(codeest)+\")\"\n",
    "        dbconn = MySQLdb.connect(host, user,passwd,bd)\n",
    "        db_cursor = dbconn.cursor()\n",
    "        db_cursor.execute(Estaciones)\n",
    "        result = np.array(db_cursor.fetchall())\n",
    "        #holding\n",
    "        risklevels=pd.DataFrame(result,columns=['codigo','action_level','minor_f','moderate_f','major_f'])\n",
    "        risklevels_all=risklevels_all.append(risklevels)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo</th>\n",
       "      <th>action_level</th>\n",
       "      <th>minor_f</th>\n",
       "      <th>moderate_f</th>\n",
       "      <th>major_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>93.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "      <td>93.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>87.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93</td>\n",
       "      <td>92.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>92.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96</td>\n",
       "      <td>82.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98</td>\n",
       "      <td>233.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>140.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>88.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104</td>\n",
       "      <td>41.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106</td>\n",
       "      <td>76.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>160.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>312.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>136.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>97.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116</td>\n",
       "      <td>115.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>421.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117</td>\n",
       "      <td>60.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124</td>\n",
       "      <td>65.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>78.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134</td>\n",
       "      <td>90.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174</td>\n",
       "      <td>40.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174</td>\n",
       "      <td>40.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>178</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>179</td>\n",
       "      <td>139.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>539.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>181</td>\n",
       "      <td>50.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>182</td>\n",
       "      <td>124.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>37.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186</td>\n",
       "      <td>80.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>187</td>\n",
       "      <td>63.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>30.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195</td>\n",
       "      <td>17.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>282.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236</td>\n",
       "      <td>51.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>238</td>\n",
       "      <td>190.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239</td>\n",
       "      <td>52.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>240</td>\n",
       "      <td>102.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245</td>\n",
       "      <td>158.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>247</td>\n",
       "      <td>38.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>251</td>\n",
       "      <td>31.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259</td>\n",
       "      <td>40.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>260</td>\n",
       "      <td>643.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>1084.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265</td>\n",
       "      <td>48.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>268</td>\n",
       "      <td>63.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>438.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>272</td>\n",
       "      <td>107.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>789</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1013</td>\n",
       "      <td>134.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>531.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1014</td>\n",
       "      <td>150.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>470.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   codigo action_level minor_f moderate_f major_f\n",
       "0      90         93.0   171.0      202.0   259.0\n",
       "0      91         93.0   126.0      353.0   501.0\n",
       "0      92         87.0   123.0      180.0   227.0\n",
       "0      93         92.0   132.0      202.0   285.0\n",
       "0      94         92.0   172.0      228.0   288.0\n",
       "0      95       -999.0  -999.0     -999.0  -999.0\n",
       "0      96         82.0   106.0      162.0   206.0\n",
       "0      97       -999.0  -999.0     -999.0  -999.0\n",
       "0      98        233.0   272.0      305.0   375.0\n",
       "0      99        140.0   210.0      260.0   350.0\n",
       "0     101         88.0   106.0      164.0   240.0\n",
       "0     102       -999.0  -999.0     -999.0  -999.0\n",
       "0     103       -999.0  -999.0     -999.0  -999.0\n",
       "0     104         41.0    64.0      114.0   182.0\n",
       "0     106         76.0    90.0      146.0   260.0\n",
       "0     108        160.0   257.0      291.0   312.0\n",
       "0     109        136.0   209.0      270.0   333.0\n",
       "0     110       -999.0  -999.0     -999.0  -999.0\n",
       "0     111       -999.0  -999.0     -999.0  -999.0\n",
       "0     115         97.0   200.0      350.0   500.0\n",
       "0     116        115.0   245.0      315.0   421.0\n",
       "0     117         60.0    80.0      132.0   178.0\n",
       "0     120       -999.0  -999.0     -999.0  -999.0\n",
       "0     123       -999.0  -999.0     -999.0  -999.0\n",
       "0     124         65.0   148.0      194.0   277.0\n",
       "0     126       -999.0  -999.0     -999.0  -999.0\n",
       "0     128         78.0   110.0      210.0   340.0\n",
       "0     130       -999.0  -999.0     -999.0  -999.0\n",
       "0     132       -999.0  -999.0     -999.0  -999.0\n",
       "0     134         90.0   180.0      250.0   320.0\n",
       "..    ...          ...     ...        ...     ...\n",
       "0     174         40.0    75.0      140.0  -999.0\n",
       "1     174         40.0    75.0      140.0  -999.0\n",
       "0     175       -999.0  -999.0     -999.0  -999.0\n",
       "0     178         38.0    61.0      111.0   179.0\n",
       "0     179        139.0   239.0      439.0   539.0\n",
       "0     181         50.0    92.0      137.0   254.0\n",
       "0     182        124.0   152.0      252.0   382.0\n",
       "0     183         37.0   121.0      236.0   284.0\n",
       "0     186         80.0   103.0      151.0   230.0\n",
       "0     187         63.0   115.0      157.0   177.0\n",
       "0     192         30.0    74.0      134.0   179.0\n",
       "0     195         17.0    50.0      100.0   200.0\n",
       "0     196        282.0   407.0      470.0   800.0\n",
       "0     236         51.0   117.0      283.0   367.0\n",
       "0     238        190.0   251.0      395.0   456.0\n",
       "0     239         52.0   123.0      214.0   264.0\n",
       "0     240        102.0   120.0      202.0   306.0\n",
       "0     245        158.0   216.0      280.0   336.0\n",
       "0     246         38.0    61.0      171.0   221.0\n",
       "0     247         38.0    92.0      138.0   278.0\n",
       "0     251         31.0    53.0       66.0    93.0\n",
       "0     259         40.0    93.0      172.0   200.0\n",
       "0     260        643.0   745.0      889.0  1084.0\n",
       "0     265         48.0    98.0      217.0   378.0\n",
       "0     268         63.0   138.0      238.0   438.0\n",
       "0     272        107.0   208.0      284.0   425.0\n",
       "0     273         50.0    60.0      126.0   153.0\n",
       "0     789       -999.0  -999.0     -999.0  -999.0\n",
       "0    1013        134.0   264.0      396.0   531.0\n",
       "0    1014        150.0   221.0      350.0   470.0\n",
       "\n",
       "[85 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risklevels_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se guarda info\n",
    "risklevels_all.to_csv('op/datos_base/risklevels_all_op.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Históricos offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# codigo de la estacion.\n",
    "codeest=est_n_ordered[0]\n",
    "# coneccion a bd con usuario operacional\n",
    "host   = '192.168.1.74'\n",
    "user   = 'siata_Oper'\n",
    "passwd = 'si@t@64512_operacional'\n",
    "bd     = 'siata'\n",
    "\n",
    "#Consulta a tabla historico_bancallena_offset\n",
    "#select fecha_hora,offset from historico_bancallena_offset where codigo='106'\n",
    "offsets=\"SELECT codigo,fecha_hora,offset FROM historico_bancallena_offset WHERE codigo=(\"+str(codeest)+\")\"\n",
    "dbconn = MySQLdb.connect(host, user,passwd,bd)\n",
    "db_cursor = dbconn.cursor()\n",
    "db_cursor.execute(offsets)\n",
    "result1 = np.array(db_cursor.fetchall())\n",
    "#holding\n",
    "offset_all=pd.DataFrame(result1,columns=['codigo','date','offset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo</th>\n",
       "      <th>date</th>\n",
       "      <th>offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>2013-12-03 12:00:00</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>2017-05-16 14:00:00</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>2017-05-16 14:40:00</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>2017-05-16 15:00:00</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>2017-10-05 12:25:00</td>\n",
       "      <td>321.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90</td>\n",
       "      <td>2017-12-19 16:25:00</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  codigo                 date  offset\n",
       "0     90  2013-12-03 12:00:00     393\n",
       "1     90  2017-05-16 14:00:00     409\n",
       "2     90  2017-05-16 14:40:00     408\n",
       "3     90  2017-05-16 15:00:00     409\n",
       "4     90  2017-10-05 12:25:00  321.94\n",
       "5     90  2017-12-19 16:25:00     343"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for ind,est in enumerate(est_n_ordered):\n",
    "    try:\n",
    "        # codigo de la estacion.\n",
    "        codeest=est_n_ordered[ind+1]\n",
    "        # coneccion a bd con usuario operacional\n",
    "        host   = '192.168.1.74'\n",
    "        user   = 'siata_Oper'\n",
    "        passwd = 'si@t@64512_operacional'\n",
    "        bd     = 'siata'\n",
    "\n",
    "        #Consulta a tabla historico_bancallena_offset\n",
    "        #select fecha_hora,offset from historico_bancallena_offset where codigo='106'\n",
    "        offsets=\"SELECT codigo,fecha_hora,offset FROM historico_bancallena_offset WHERE codigo=(\"+str(codeest)+\")\"\n",
    "        dbconn = MySQLdb.connect(host, user,passwd,bd)\n",
    "        db_cursor = dbconn.cursor()\n",
    "        db_cursor.execute(offsets)\n",
    "        result1 = np.array(db_cursor.fetchall())\n",
    "        #holding\n",
    "        offsetH=pd.DataFrame(result1,columns=['codigo','date','offset'])\n",
    "        offset_all=offset_all.append(offsetH)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo</th>\n",
       "      <th>date</th>\n",
       "      <th>offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>2013-12-03 12:00:00</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>2017-05-16 14:00:00</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>2017-05-16 14:40:00</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>2017-05-16 15:00:00</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>2017-10-05 12:25:00</td>\n",
       "      <td>321.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "      <td>2014-03-14 12:00:00</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>2012-06-14 12:00:00</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>2017-03-31 11:20:00</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93</td>\n",
       "      <td>2012-04-13 12:00:00</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>2012-04-11 12:00:00</td>\n",
       "      <td>1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "      <td>2017-10-26 09:54:00</td>\n",
       "      <td>1051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96</td>\n",
       "      <td>2011-11-03 12:00:00</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96</td>\n",
       "      <td>2017-03-22 13:30:00</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96</td>\n",
       "      <td>2017-03-23 12:30:00</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98</td>\n",
       "      <td>2011-07-25 12:00:00</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98</td>\n",
       "      <td>2017-07-14 13:00:00</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>2011-07-19 12:00:00</td>\n",
       "      <td>1285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>2013-12-19 12:00:00</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>2017-05-31 14:00:00</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104</td>\n",
       "      <td>2013-12-27 12:00:00</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104</td>\n",
       "      <td>2017-05-31 12:00:00</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104</td>\n",
       "      <td>2017-09-12 10:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106</td>\n",
       "      <td>2014-01-16 12:00:00</td>\n",
       "      <td>684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>2017-08-10 12:30:00</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106</td>\n",
       "      <td>2017-10-09 15:00:00</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106</td>\n",
       "      <td>2017-11-03 11:14:00</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>2014-03-10 12:00:00</td>\n",
       "      <td>410.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>2014-03-11 12:00:00</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>2017-03-30 16:00:00</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109</td>\n",
       "      <td>2017-10-24 10:30:00</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174</td>\n",
       "      <td>2017-08-09 11:00:00</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>178</td>\n",
       "      <td>2016-05-13 12:00:00</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>178</td>\n",
       "      <td>2017-06-06 12:00:00</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>178</td>\n",
       "      <td>2017-11-08 14:30:00</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>179</td>\n",
       "      <td>2016-09-23 12:00:00</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "      <td>2017-08-10 11:00:00</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>181</td>\n",
       "      <td>2016-11-23 12:00:00</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>182</td>\n",
       "      <td>2016-11-25 12:00:00</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>2016-12-20 12:00:00</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186</td>\n",
       "      <td>2017-04-04 00:00:00</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>2017-11-21 10:30:00</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>187</td>\n",
       "      <td>2017-06-06 00:00:00</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>187</td>\n",
       "      <td>2017-11-10 14:20:00</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>2017-07-07 00:00:00</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195</td>\n",
       "      <td>2017-05-05 00:00:00</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>2017-08-08 00:00:00</td>\n",
       "      <td>1063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196</td>\n",
       "      <td>2017-10-14 14:00:00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>238</td>\n",
       "      <td>2017-09-25 17:25:00</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238</td>\n",
       "      <td>2017-10-24 03:00:00</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245</td>\n",
       "      <td>2017-10-26 11:04:00</td>\n",
       "      <td>991.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246</td>\n",
       "      <td>2017-11-02 10:07:00</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>247</td>\n",
       "      <td>2017-11-03 14:56:00</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>251</td>\n",
       "      <td>2017-11-21 12:41:00</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259</td>\n",
       "      <td>2017-12-01 16:30:00</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>260</td>\n",
       "      <td>2017-11-28 16:00:00</td>\n",
       "      <td>1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1013</td>\n",
       "      <td>2017-04-14 00:00:00</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1014</td>\n",
       "      <td>2017-07-02 00:00:00</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1014</td>\n",
       "      <td>2017-07-05 13:40:00</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1014</td>\n",
       "      <td>2017-07-08 08:00:00</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1014</td>\n",
       "      <td>2017-09-26 17:38:00</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   codigo                 date  offset\n",
       "0      90  2013-12-03 12:00:00     393\n",
       "1      90  2017-05-16 14:00:00     409\n",
       "2      90  2017-05-16 14:40:00     408\n",
       "3      90  2017-05-16 15:00:00     409\n",
       "4      90  2017-10-05 12:25:00  321.94\n",
       "0      91  2014-03-14 12:00:00     715\n",
       "0      92  2012-06-14 12:00:00     525\n",
       "1      92  2017-03-31 11:20:00     525\n",
       "0      93  2012-04-13 12:00:00     985\n",
       "0      94  2012-04-11 12:00:00    1075\n",
       "1      94  2017-10-26 09:54:00    1051\n",
       "0      96  2011-11-03 12:00:00     300\n",
       "1      96  2017-03-22 13:30:00     277\n",
       "2      96  2017-03-23 12:30:00     300\n",
       "0      98  2011-07-25 12:00:00    1034\n",
       "1      98  2017-07-14 13:00:00     830\n",
       "0      99  2011-07-19 12:00:00    1285\n",
       "0     101  2013-12-19 12:00:00     572\n",
       "1     101  2017-05-31 14:00:00     413\n",
       "0     104  2013-12-27 12:00:00     314\n",
       "1     104  2017-05-31 12:00:00     288\n",
       "2     104  2017-09-12 10:00:00       2\n",
       "0     106  2014-01-16 12:00:00     684\n",
       "1     106  2017-08-10 12:30:00     670\n",
       "2     106  2017-10-09 15:00:00     6.7\n",
       "3     106  2017-11-03 11:14:00     647\n",
       "0     108  2014-03-10 12:00:00  410.62\n",
       "0     109  2014-03-11 12:00:00     390\n",
       "1     109  2017-03-30 16:00:00     366\n",
       "2     109  2017-10-24 10:30:00     370\n",
       "..    ...                  ...     ...\n",
       "1     174  2017-08-09 11:00:00     180\n",
       "0     178  2016-05-13 12:00:00     268\n",
       "1     178  2017-06-06 12:00:00     180\n",
       "2     178  2017-11-08 14:30:00     184\n",
       "0     179  2016-09-23 12:00:00     667\n",
       "1     179  2017-08-10 11:00:00     645\n",
       "0     181  2016-11-23 12:00:00     217\n",
       "0     182  2016-11-25 12:00:00     435\n",
       "0     183  2016-12-20 12:00:00     590\n",
       "0     186  2017-04-04 00:00:00     274\n",
       "1     186  2017-11-21 10:30:00     284\n",
       "0     187  2017-06-06 00:00:00     198\n",
       "1     187  2017-11-10 14:20:00     180\n",
       "0     192  2017-07-07 00:00:00     214\n",
       "0     195  2017-05-05 00:00:00     286\n",
       "0     196  2017-08-08 00:00:00    1063\n",
       "1     196  2017-10-14 14:00:00      10\n",
       "0     238  2017-09-25 17:25:00     597\n",
       "1     238  2017-10-24 03:00:00     565\n",
       "0     245  2017-10-26 11:04:00   991.3\n",
       "0     246  2017-11-02 10:07:00     341\n",
       "0     247  2017-11-03 14:56:00     342\n",
       "0     251  2017-11-21 12:41:00     270\n",
       "0     259  2017-12-01 16:30:00     242\n",
       "0     260  2017-11-28 16:00:00    1205\n",
       "0    1013  2017-04-14 00:00:00     610\n",
       "0    1014  2017-07-02 00:00:00     580\n",
       "1    1014  2017-07-05 13:40:00     600\n",
       "2    1014  2017-07-08 08:00:00     610\n",
       "3    1014  2017-09-26 17:38:00     606\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Guardar info\n",
    "offset_all.to_csv('op/datos_base/offsetsH_all_op.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chequear hexadecimal de colores \n",
    "\n",
    "lcolors=['g','orange','orangered','indigo']\n",
    "import matplotlib\n",
    "print matplotlib.colors.cnames['darkgray']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estaciones_datos_all.loc[estaciones_datos_all['codigo'].isin(est_nordered_list)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coordenadas y nombres de estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "codeest=est_n_ordered[0]\n",
    "# coneccion a bd con usuario operacional\n",
    "host   = '192.168.1.74'\n",
    "user   = 'siata_Oper'\n",
    "passwd = 'si@t@64512_operacional'\n",
    "bd     = 'siata'\n",
    "#Consulta a tabla estaciones\n",
    "Estaciones=\"SELECT codigo,longitude,latitude,nombreestacion  FROM estaciones WHERE codigo=(\"+str(codeest)+\")\"\n",
    "dbconn = MySQLdb.connect(host, user,passwd,bd)\n",
    "db_cursor = dbconn.cursor()\n",
    "db_cursor.execute(Estaciones)\n",
    "result = np.array(db_cursor.fetchall())\n",
    "estaciones_datos_all=pd.DataFrame(result,columns=['codigo','longitud','latitud','nombreestacion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ind,est in enumerate(est_n_ordered):\n",
    "    try:\n",
    "        # codigo de la estacion.\n",
    "        codeest=est_n_ordered[ind+1]\n",
    "        # coneccion a bd con usuario operacional\n",
    "        host   = '192.168.1.74'\n",
    "        user   = 'siata_Oper'\n",
    "        passwd = 'si@t@64512_operacional'\n",
    "        bd     = 'siata'\n",
    "        #Consulta a tabla estaciones\n",
    "        Estaciones=\"SELECT codigo,longitude,latitude,nombreestacion  FROM estaciones WHERE codigo=(\"+str(codeest)+\")\"\n",
    "        dbconn = MySQLdb.connect(host, user,passwd,bd)\n",
    "        db_cursor = dbconn.cursor()\n",
    "        db_cursor.execute(Estaciones)\n",
    "        result = np.array(db_cursor.fetchall())\n",
    "        #holding\n",
    "        estaciones_datos=pd.DataFrame(result,columns=['codigo','longitud','latitud','nombreestacion'])\n",
    "        estaciones_datos_all=estaciones_datos_all.append(estaciones_datos)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estaciones_datos_all=estaciones_datos_all.drop_duplicates(subset='codigo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estaciones_datos_all.to_msgpack('../series/estaciones_datos_op.msg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## no se si sevirá"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nivel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diccionario estático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nombre estacion\n",
    "- Coordenadas\n",
    "- Shp cuenca\n",
    "- AGREGAR: kml de estacions de nivel!!!!\n",
    "\n",
    "Las coordenadas de las alarmas con sus nombres, están en este msg:\n",
    "     \n",
    "        '../series/op/nombres_sirenas_op.msg'\n",
    "        \n",
    "Este se va a actualizar sólo cuando se agreguen nuevas estaciones de nivel asociadas a alarmas y sirenas, la mayoría del tiempo es estático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#------------------------------------\n",
    "##coordenadas y nombres de estaciones\n",
    "#------------------------------------\n",
    "\n",
    "est_datos=pd.read_msgpack('../series/op/estaciones_datos_op.msg')#####################################################\n",
    "\n",
    "# se crean dicts.\n",
    "lon_lat={};nombreestacion={};nombrealarma={};nombrecorriente={}\n",
    "for est in n_alarmas:\n",
    "    #se obtiene y guarda los datos de las n_alarmas\n",
    "    datos=np.array(est_datos.loc[est_datos['codigo']==str(est)])[0][1:]\n",
    "    lon_lat.update({str(est):(datos[0],datos[1])})\n",
    "    nombreestacion.update({str(est):datos[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Escribe diccionario para json\n",
    "dictt={}\n",
    "dictt.update({'lon_lat':lon_lat})\n",
    "dictt.update({'Nombre Estacion':nombreestacion})\n",
    "\n",
    "df=pd.DataFrame.from_dict(dictt)\n",
    "df.to_json('prueba_jsonnivel_estatico_op.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nombre Estacion': {'108': 'Santa Rita - San Antonio de Prado',\n",
       "  '135': 'Q. La loca - Nivel',\n",
       "  '173': 'Q. Picacha - Aguas Frias',\n",
       "  '179': 'La Inmaculada - Nivel',\n",
       "  '186': 'Q. La Gallinaza',\n",
       "  '246': 'Q. La Raya - Nivel',\n",
       "  '251': 'Q.  la L\\xf3pez - Nivel',\n",
       "  '259': 'Andaluc\\xeda Caldas - Nivel'},\n",
       " 'lon_lat': {'108': ('-75.651535', '6.190568'),\n",
       "  '135': ('-75.5608889', '6.3236944'),\n",
       "  '173': ('-75.639668', '6.231477'),\n",
       "  '179': ('-75.633503', '6.136677'),\n",
       "  '186': ('-75.3277100', '6.4329150'),\n",
       "  '246': ('-75.64090', '6.11194'),\n",
       "  '251': ('-75.32507', '6.42794'),\n",
       "  '259': ('-75.62651', '6.09259')}}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dflol=pd.read_json('../../../series/op/prueba_jsonnivel_estatico_op.json')\n",
    "dflol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!Not longer useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#see leen las rutas\n",
    "rutes=glob.glob(al.get_ruta(listconfig,'ruta_nivel')+'*')\n",
    "#se deduce la estacion de cada archivo para luego organizarlos en orden\n",
    "est_n=np.array([int(rute.split('/')[-1].split('_')[0]) for rute in rutes])\n",
    "#orden para organizarlos\n",
    "order_est=est_n.argsort()\n",
    "#se ordenan \n",
    "est_n_ordered=np.take(est_n,order_est)\n",
    "rutes_ordered=np.take(rutes,order_est)\n",
    "#est - alarmas\n",
    "n_alarmas=np.sort(np.hstack(dfconfig['EstNivel']))###########ASIGNACION DE ESTACIONES.\n",
    "#pos de los archivos correspondientes a alarmas - se dan todas esas vueltas para evitar un for para todas las est de nivel\n",
    "pos_al=est_n_ordered.searchsorted(n_alarmas) #****REVISAAR, esta función busca las pos en est_n_ordered donde deberían estar n_alarmas para estar organizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying to write kml from python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kml=simplekml.Kml()\n",
    "names=[]\n",
    "for est in estaciones:\n",
    "    name=kml.newpoint(name=infoestaciones['NombreEstacion'][infoestaciones.index==est][est],\n",
    "                coords=[(float(infoestaciones['Longitude'][infoestaciones.index==est][est]),float(infoestaciones['Latitude'][infoestaciones.index==est][est]))])\n",
    "    names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<kml xmlns=\"http://www.opengis.net/kml/2.2\" xmlns:gx=\"http://www.google.com/kml/ext/2.2\">\n",
      "    <Document id=\"feat_15\">\n",
      "        <Placemark id=\"feat_16\">\n",
      "            <name>Colegio Campestre el Encanto</name>\n",
      "            <Point id=\"geom_12\">\n",
      "                <coordinates>-75.661333,6.1953667,0.0</coordinates>\n",
      "            </Point>\n",
      "        </Placemark>\n",
      "        <Placemark id=\"feat_17\">\n",
      "            <name>3 Aguas - Nivel</name>\n",
      "            <Point id=\"geom_13\">\n",
      "                <coordinates>-75.63526,6.09602,0.0</coordinates>\n",
      "            </Point>\n",
      "        </Placemark>\n",
      "        <Placemark id=\"feat_18\">\n",
      "            <name>Santa Rita - San Antonio de Prado</name>\n",
      "            <Point id=\"geom_14\">\n",
      "                <coordinates>-75.651535,6.190568,0.0</coordinates>\n",
      "            </Point>\n",
      "        </Placemark>\n",
      "        <Placemark id=\"feat_19\">\n",
      "            <name>Caldas-Unidad Deportiva</name>\n",
      "            <Point id=\"geom_15\">\n",
      "                <coordinates>-75.633048,6.088251,0.0</coordinates>\n",
      "            </Point>\n",
      "        </Placemark>\n",
      "        <Placemark id=\"feat_20\">\n",
      "            <name>Q. Picacha - Aguas Frias</name>\n",
      "            <Point id=\"geom_16\">\n",
      "                <coordinates>-75.639668,6.231477,0.0</coordinates>\n",
      "            </Point>\n",
      "        </Placemark>\n",
      "        <Placemark id=\"feat_21\">\n",
      "            <name>Q. Picacha - Aguas Frias</name>\n",
      "            <Point id=\"geom_17\">\n",
      "                <coordinates>-75.639668,6.231477,0.0</coordinates>\n",
      "            </Point>\n",
      "        </Placemark>\n",
      "        <Placemark id=\"feat_22\">\n",
      "            <name>La Inmaculada - Nivel</name>\n",
      "            <Point id=\"geom_18\">\n",
      "                <coordinates>-75.633503,6.136677,0.0</coordinates>\n",
      "            </Point>\n",
      "        </Placemark>\n",
      "        <Placemark id=\"feat_23\">\n",
      "            <name>Q. La Gallinaza</name>\n",
      "            <Point id=\"geom_19\">\n",
      "                <coordinates>-75.32771,6.432915,0.0</coordinates>\n",
      "            </Point>\n",
      "        </Placemark>\n",
      "        <Placemark id=\"feat_24\">\n",
      "            <name>Q. La Raya - Nivel</name>\n",
      "            <Point id=\"geom_20\">\n",
      "                <coordinates>-75.6409,6.11194,0.0</coordinates>\n",
      "            </Point>\n",
      "        </Placemark>\n",
      "        <Placemark id=\"feat_25\">\n",
      "            <name>Q.  la Lopez - Nivel</name>\n",
      "            <Point id=\"geom_21\">\n",
      "                <coordinates>-75.324997,6.429716,0.0</coordinates>\n",
      "            </Point>\n",
      "        </Placemark>\n",
      "        <Placemark id=\"feat_26\">\n",
      "            <name>Andalucia Caldas - Nivel</name>\n",
      "            <Point id=\"geom_22\">\n",
      "                <coordinates>-75.62651,6.09259,0.0</coordinates>\n",
      "            </Point>\n",
      "        </Placemark>\n",
      "        <Placemark id=\"feat_27\">\n",
      "            <name>Q. La loca El cafetal - Nivel</name>\n",
      "            <Point id=\"geom_23\">\n",
      "                <coordinates>-75.58002,6.31582,0.0</coordinates>\n",
      "            </Point>\n",
      "        </Placemark>\n",
      "    </Document>\n",
      "</kml>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print kml.kml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kml.newschemaope\n",
    "\n",
    "print simplekml.SimpleField(name='Nact',type='float')\n",
    "\n",
    "simplekml.SimpleData(name='Nact',value='0.27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kml1=simplekml.SimpleField(name='Nact',type='float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pykml.factory import KML_ElementMaker as KML\n",
    "from pykml.factory import ATOM_ElementMaker as ATOM\n",
    "from pykml.factory import GX_ElementMaker as GX\n",
    "from lxml import etree\n",
    "from pykml import parser\n",
    "from pykml.factory import nsmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rutakml='/media/nicolas/Home/Jupyter/Soraya/git/Alarmas/04_web_hidrologia/hidrologia/op/kml/ubicacion_gral/estnivel_al.kml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "no such child: {http://www.opengis.net/kml/2.2}name",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-2254a7210ef2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPlacemark\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mlxml.objectify.pyx\u001b[0m in \u001b[0;36mlxml.objectify.ObjectifiedElement.__getattr__ (src/lxml/lxml.objectify.c:3563)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mlxml.objectify.pyx\u001b[0m in \u001b[0;36mlxml.objectify._lookupChildOrRaise (src/lxml/lxml.objectify.c:5873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: no such child: {http://www.opengis.net/kml/2.2}name"
     ]
    }
   ],
   "source": [
    "with open(rutakml) as f:\n",
    "    folder = parser.parse(f).getroot().Document.Folder\n",
    "\n",
    "# for pm in folder.Placemark:\n",
    "#     print(pm.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "namespace = {\"ns\": nsmap[None]}\n",
    "\n",
    "with open(rutakml) as f:\n",
    "    root = parser.parse(f).getroot()\n",
    "    pms = root.findall(\".//ns:Placemark\", namespaces=namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " from os import path\n",
    "kml_file = path.join(rutakml)\n",
    "    \n",
    "with open(kml_file) as f:\n",
    "    doc = parser.parse(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/nicolas/Home/Jupyter/Soraya/git/Alarmas/04_web_hidrologia/hidrologia/op/kml/ubicacion_gral/estnivel_al.kml'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kml_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_object = KML.name(\"Hello World!\")\n",
    "\n",
    "pm1 = KML.Placemark(\n",
    "            KML.name(\"Hello World!\"),\n",
    "            KML.Point(\n",
    "               KML.coordinates(\"-64.5253,18.4607\")\n",
    "             )\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Placemark xmlns:gx=\"http://www.google.com/kml/ext/2.2\" xmlns:atom=\"http://www.w3.org/2005/Atom\" xmlns=\"http://www.opengis.net/kml/2.2\">\n",
      "  <name>Hello World!</name>\n",
      "  <Point>\n",
      "    <coordinates>-64.5253,18.4607</coordinates>\n",
      "  </Point>\n",
      "</Placemark>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print etree.tostring(pm1, pretty_print=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
